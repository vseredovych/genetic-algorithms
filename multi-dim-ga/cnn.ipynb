{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from utils import convolve2D\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from ipywidgets import IntProgress\n",
    "from scipy.signal import convolve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond=np.any([y_train_full==1,y_train_full==3],0)\n",
    "X_train_full=X_train_full[cond]\n",
    "y_train_full=y_train_full[cond]\n",
    "\n",
    "X_test=X_test[np.any([y_test==1,y_test==3],0)]\n",
    "y_test=y_test[np.any([y_test==1,y_test==3],0)]\n",
    "\n",
    "y_train_full=(y_train_full==3).astype(int)\n",
    "y_test=(y_test==3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (11000, 28, 28), (1000, 28, 28)\n",
      "y train shape: (11000,), (1000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid = X_train_full[:-1000], X_train_full[-1000:]\n",
    "y_train, y_valid = y_train_full[:-1000], y_train_full[-1000:]\n",
    "print(f\"X train shape: {X_train.shape}, {X_valid.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}, {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_valid = (X_valid - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def convolve2D(image, kernel, padding=0, strides=1, flip=True):\n",
    "    # Cross Correlation. Reversing matrix.\n",
    "    if flip:\n",
    "        kernel = np.flipud(np.fliplr(kernel))\n",
    "\n",
    "    # Gather Shapes of Kernel + Image + Padding\n",
    "    xKernShape = kernel.shape[0]\n",
    "    yKernShape = kernel.shape[1]\n",
    "    xImgShape = image.shape[0]\n",
    "    yImgShape = image.shape[1]\n",
    "\n",
    "    # Shape of Output Convolution\n",
    "    xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\n",
    "    yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\n",
    "    output = np.zeros((xOutput, yOutput))\n",
    "\n",
    "    # Apply Equal Padding to All Sides\n",
    "    if padding != 0:\n",
    "        imagePadded = np.zeros((image.shape[0] + padding*2, image.shape[1] + padding*2))\n",
    "        imagePadded[int(padding):int(-1 * padding), int(padding):int(-1 * padding)] = image\n",
    "    else:\n",
    "        imagePadded = image\n",
    "\n",
    "    # Iterate through image\n",
    "    for y in range(imagePadded.shape[1]):\n",
    "        # Exit Convolution\n",
    "        if y > imagePadded.shape[1] - yKernShape:\n",
    "            break\n",
    "        # Only Convolve if y has gone down by the specified Strides\n",
    "        if y % strides == 0:\n",
    "            for x in range(imagePadded.shape[0]):\n",
    "                # Go to next row once kernel is out of bounds\n",
    "                if x > imagePadded.shape[0] - xKernShape:\n",
    "                    break\n",
    "\n",
    "                # Only Convolve if x has moved by the specified Strides\n",
    "                if x % strides == 0:\n",
    "                    output[x, y] = (kernel * imagePadded[x: x + xKernShape, y: y + yKernShape]).sum()\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def cost_function():\n",
    "        pass\n",
    "    \n",
    "    def forward_propagation(self, W1, W2, X, y):\n",
    "        l0=X\n",
    "        \n",
    "        # Embed the image in a bigger image. It would be useful in computing corrections to the convolution\n",
    "        # filter\n",
    "        lt0=np.zeros((l0.shape[0]+K-1,l0.shape[1]+K-1))\n",
    "        lt0[K//2:-K//2+1,K//2:-K//2+1]=l0\n",
    "        \n",
    "        # convolve with the filter\n",
    "        l0_conv=convolve(l0,W1[::-1,::-1],'same','direct')\n",
    "        \n",
    "        # Layer one is Relu applied on the convolution \n",
    "        l1=relu(l0_conv)\n",
    "        \n",
    "        # Also compute derivative of layer 1\n",
    "        f1p=relu_prime(l0_conv)\n",
    "\n",
    "        # Compute layer 2\n",
    "        l2=sigmoid(np.dot(l1.reshape(-1,),W2))\n",
    "        l2=l2.clip(10**-16,1-10**-16)\n",
    "        \n",
    "        # Loss and Accuracy\n",
    "        loss=-(y*np.log(l2)+(1-y)*np.log(1-l2))\n",
    "        accuracy=int(y==np.where(l2>0.5,1,0))\n",
    "        \n",
    "        return accuracy, loss, lt0\n",
    "        \n",
    "    def backward_propagation(self, X, Y, cache):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X_vert, Y_vert):\n",
    "        K=3\n",
    "        image_size=X_train.shape[1]\n",
    "        image_size_embedding_size=image_size+K-1\n",
    "\n",
    "        print(\"image_size: \", image_size)\n",
    "        print(\"image_size_embedding_size (after convolution): \", image_size_embedding_size)\n",
    "\n",
    "        np.random.seed(42)\n",
    "        W1=np.random.normal(0,2/np.sqrt(K*K),size=(K,K))\n",
    "        W2=np.random.normal(0,1/np.sqrt(image_size*image_size),size=(image_size*image_size))\n",
    "\n",
    "        W1_original=W1.copy()\n",
    "        W2_original=W2.copy()\n",
    "\n",
    "        print(W1.shape)\n",
    "        print(W2.shape)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def predict(self, X_vert):\n",
    "        pass\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.where(x>0,x,0)\n",
    "\n",
    "    def relu_prime(self, x):\n",
    "        return np.where(x>0,1,0)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1./(1.+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import numpy as np\n",
    "from scipy.special import erf\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.where(x>0,x,0)\n",
    "    \n",
    "def relu_prime(x):\n",
    "    return np.where(x>0,1,0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1.+np.exp(-x))\n",
    "\n",
    "def forward_pass(W1,W2,X,y):\n",
    "    l0=X\n",
    "    l0_conv=convolve(l0,W1[::-1,::-1],'same','direct')    \n",
    "\n",
    "    l1=relu(l0_conv)    \n",
    "    l2=sigmoid(np.dot(l1.reshape(-1,),W2))\n",
    "    l2=l2.clip(10**-16,1-10**-16)    \n",
    "    loss=-(y*np.log(l2)+(1-y)*np.log(1-l2))\n",
    "    accuracy=int(y==np.where(l2>0.5,1,0))    \n",
    "    return accuracy,loss\n",
    "\n",
    "def coroutine(func):\n",
    "    @wraps(func)\n",
    "    def inner(*args, **kwargs):\n",
    "        gen = func(*args, **kwargs)\n",
    "        next(gen)\n",
    "        return gen\n",
    "\n",
    "    return inner\n",
    "\n",
    "@coroutine\n",
    "def averager():\n",
    "    total = 0\n",
    "    count = 0\n",
    "    average = None\n",
    "    cont = True\n",
    "    while cont:\n",
    "        val = yield average\n",
    "        if val is None:\n",
    "            cont = False\n",
    "            continue\n",
    "        else:\n",
    "            total += val\n",
    "            count += 1.\n",
    "            average = total / count\n",
    "    return average\n",
    "\n",
    "\n",
    "def extract_averager_value(averager):\n",
    "    try:\n",
    "        averager.send(None)\n",
    "    except StopIteration as e:\n",
    "        return e.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size:  28\n",
      "image_size_embedding_size (after convolution):  30\n"
     ]
    }
   ],
   "source": [
    "# filter size\n",
    "K=3\n",
    "image_size=X_train.shape[1]\n",
    "image_size_embedding_size=image_size+K-1\n",
    "\n",
    "print(\"image_size: \", image_size)\n",
    "print(\"image_size_embedding_size (after convolution): \", image_size_embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "W1=np.random.normal(0,2/np.sqrt(K*K),size=(K,K))\n",
    "W2=np.random.normal(0,1/np.sqrt(image_size*image_size),size=(image_size*image_size))\n",
    "\n",
    "W1_original = W1.copy()\n",
    "W2_original = W2.copy()\n",
    "\n",
    "print(W1.shape)\n",
    "print(W2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, y, W1, W2):\n",
    "    # First layer is just the input\n",
    "    l0=X\n",
    "\n",
    "    # Embed the image in a bigger image. It would be useful in computing corrections to the convolution\n",
    "    # filter\n",
    "    lt0=np.zeros((l0.shape[0]+K-1,l0.shape[1]+K-1))\n",
    "    lt0[K//2:-K//2+1,K//2:-K//2+1]=l0\n",
    "\n",
    "    #### FORWARD\n",
    "    # convolve with the filter\n",
    "    #l0_conv=convconvolveolve2D(l0,W1[::-1,::-1],'same','direct')\n",
    "    l0_conv=convolve2D(l0, W1, padding=1, strides=1, flip=False)\n",
    "\n",
    "    # Layer one is Relu applied on the convolution \n",
    "    l1=relu(l0_conv)\n",
    "\n",
    "    # Also compute derivative of layer 1\n",
    "    f1p=relu_prime(l0_conv)\n",
    "\n",
    "    # Compute layer 2\n",
    "    l2=sigmoid(np.dot(l1.reshape(-1,),W2))\n",
    "    l2=l2.clip(10**-16,1-10**-16)\n",
    "\n",
    "    \n",
    "    loss = -(y*np.log(l2)+(1-y)*np.log(1-l2))\n",
    "    accuracy = int(y==np.where(l2>0.5,1,0))\n",
    "    \n",
    "    return accuracy, loss, l1, l2, lt0, f1p\n",
    "\n",
    "def back_propagation(y, l1, l2, lt0, f1p):\n",
    "    # Derivative of loss wrt the dense layer\n",
    "    dW2=(((1-y)*l2-y*(1-l2))*l1).reshape(-1,)\n",
    "\n",
    "    # Derivative of loss wrt the output of the first layer\n",
    "    dl1=(((1-y)*l2-y*(1-l2))*W2).reshape(28,28)\n",
    "\n",
    "    # Derivative of the loss wrt the convolution filter\n",
    "    dl1_f1p=dl1*f1p\n",
    "    dW1=np.array([\n",
    "        [(lt0[alpha:+alpha+image_size,beta:beta+image_size]*dl1_f1p).sum() for beta in range(K)] \\\n",
    "                      for alpha in range(K)\n",
    "    ])\n",
    "\n",
    "    return dW1, dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd14d426067a4bbf8e0221a09d7ada3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=11000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 0.06, train acc 0.98, valid loss 0.09, valid acc 0.97\n",
      "Epoch 2: train loss 0.05, train acc 0.98, valid loss 0.09, valid acc 0.97\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "w=IntProgress(max=len(y_train))\n",
    "display(w)\n",
    "eta=.001\n",
    "\n",
    "for epoch in range(2):\n",
    "    train_loss=averager()\n",
    "    train_accuracy=averager()\n",
    "    \n",
    "    for i in range(len(y_train)):\n",
    "        \n",
    "        # Take a random sample\n",
    "        k=np.random.randint(len(y_train))\n",
    "        X=X_train[k]\n",
    "        y=y_train[k]\n",
    "        if (i+1) % 100 ==0:\n",
    "            w.value=i+1\n",
    "        \n",
    "        accuracy, loss, l1, l2, lt0, f1p = forward_propagation(X, y, W1, W2)\n",
    "        \n",
    "        dW1, dW2 = back_propagation(y, l1, l2, lt0, f1p)\n",
    "\n",
    "        # Save the loss and accuracy to a running averager\n",
    "        train_loss.send(loss)\n",
    "        train_accuracy.send(accuracy)\n",
    "\n",
    "        W2+=-eta*dW2\n",
    "        W1+=-eta*dW1\n",
    "\n",
    "    \n",
    "    loss_averager_valid=averager()\n",
    "    accuracy_averager_valid=averager()   \n",
    "    \n",
    "    for X,y in zip(X_valid,y_valid):\n",
    "        accuracy,loss=forward_pass(W1,W2,X,y)\n",
    "        loss_averager_valid.send(loss)\n",
    "        accuracy_averager_valid.send(accuracy)\n",
    "    \n",
    "    train_loss, train_accuracy, valid_loss, valid_accuracy = map(extract_averager_value,[\n",
    "                                                                train_loss,\n",
    "                                                                train_accuracy,\n",
    "                                                                loss_averager_valid,\n",
    "                                                                accuracy_averager_valid]\n",
    "                                                               )\n",
    "    msg='Epoch {}: train loss {:.2f}, train acc {:.2f}, valid loss {:.2f}, valid acc {:.2f}'.format(epoch+1,\n",
    "                                                                                                      train_loss,\n",
    "                                                                                                      train_accuracy,\n",
    "                                                                                                      valid_loss,\n",
    "                                                                                                      valid_accuracy\n",
    "                                                                                                     )\n",
    "    print(msg)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward_pass_for_plot(W1,W2,X,y):\n",
    "#     l0=X\n",
    "#     l0_conv=convolve(l0,W1[::-1,::-1],'same','direct')\n",
    "\n",
    "#     l1=relu(l0_conv)\n",
    "\n",
    "#     l2=sigmoid(np.dot(l1.reshape(-1,),W2))\n",
    "#     l2=l2.clip(10**-16,1-10**-16)\n",
    "\n",
    "\n",
    "#     loss=-(y*np.log(l2)+(1-y)*np.log(1-l2))\n",
    "#     accuracy=int(y==np.where(l2>0.5,1,0))\n",
    "\n",
    "#     return l1,l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_figs(i):\n",
    "#     _,axs=plt.subplots(1,3,figsize=(10,3))\n",
    "#     axs[0].imshow(X_train[i],cmap='gray')\n",
    "#     l1_original,l2_original=forward_pass_for_plot(W1_original,W2_original,X_train[i],y_train[i])\n",
    "#     axs[1].imshow(l1_original,cmap='gray')\n",
    "#     l1,l2=forward_pass_for_plot(W1,W2,X_train[i],y_train[i])\n",
    "#     axs[2].imshow(l1,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(W1,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(W2.reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     plot_figs(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
